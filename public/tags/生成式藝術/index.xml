<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>生成式藝術 on </title>
    <link>/tags/%E7%94%9F%E6%88%90%E5%BC%8F%E8%97%9D%E8%A1%93/</link>
    <description>Recent content in 生成式藝術 on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 21 May 2023 13:52:02 +0000</lastBuildDate>
    <atom:link href="/tags/%E7%94%9F%E6%88%90%E5%BC%8F%E8%97%9D%E8%A1%93/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>人類和 AI 組樂團的時代不遠！Google 正測試 MusicLM 人工智慧</title>
      <link>/zh-tw/post/%E4%BA%BA%E9%A1%9E%E5%92%8C-ai-%E7%B5%84%E6%A8%82%E5%9C%98%E7%9A%84%E6%99%82%E4%BB%A3%E4%B8%8D%E9%81%A0google-%E6%AD%A3%E6%B8%AC%E8%A9%A6-musiclm-%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7/</link>
      <pubDate>Sun, 21 May 2023 13:52:02 +0000</pubDate>
      <guid>/zh-tw/post/%E4%BA%BA%E9%A1%9E%E5%92%8C-ai-%E7%B5%84%E6%A8%82%E5%9C%98%E7%9A%84%E6%99%82%E4%BB%A3%E4%B8%8D%E9%81%A0google-%E6%AD%A3%E6%B8%AC%E8%A9%A6-musiclm-%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7/</guid>
      <description>不是回答問題，而是生成音樂&#xA;今年一月 Google 發表了名為 「 MusicLM 」的人工智慧，它可以接受文字和音樂提示來創作音樂。比方說，收到類似「 適合晚餐派對的靈魂味爵士樂 」或是「 祥和的小提琴旋律配上破音的吉他伴奏 」這樣的提示後，AI 將產生兩段音樂供選擇，並且根據使用者的選擇來優化人工智能模型。如果不想用文字、也可以提供一段音訊，因此不需演奏樂器也能透過哼唱和 AI 溝通。&#xA;MusicLM 現在能完成的事&#xA;在官方釋出的影片中，已經可以看到：&#xA;AI 接收到人類的歌唱後，將其轉換為樂器演奏，影片中的例子是薩克斯風。 人類演奏實體音樂的同時，AI 會建議一些可能適合產生的音樂曲風。 AI 接收到人類的歌唱後，將其轉換為薩克斯風的演奏。產生伴奏音樂。假設你是一個樂手，一時找不到樂團成員，AI 就可以幫你產生一些伴奏音樂。 另外一個有趣的實驗，則是用文字描述名畫，並提供給 MusicLM 來產生音樂，包含達利和馬諦斯等著名畫家的作品。&#xA;對未來音樂創作的想像&#xA;MusicLM 正處在開發階段，還不是成熟的人工智慧，但音樂愛好者已經開始想像 AI 能夠如何幫助人類，這邊有些天馬行空的個人想法：&#xA;既然可以伴奏，也能夠辨識音樂的風格和情緒，那能否根據樂手的演奏來即時配合？ 接受樂手的語音指示：「 變換和弦 」、「 慢ㄧ點！」⋯？ 延伸特定歌曲：「給我 20 個類似 xxx 歌手 ooo 曲目的節奏，然後加上這段旋律。」？ 和音樂軟體合作。要是可以把 MusicLM 產生的音樂分軌輸出，然後再匯入 Ableton 編輯，可用性不知怎樣？或者乾脆內建在 Ableton 裡面然後收個授權費？ MusicLM 已開放給有興趣的用戶去 AI Test Kitchen 登記 beta。想試聽看看 MusicLM 產生的音樂也可到這邊。</description>
    </item>
  </channel>
</rss>
